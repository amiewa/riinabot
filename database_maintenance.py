"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å‰Šé™¤ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½
"""

import logging
import shutil
import gzip
from datetime import datetime, timedelta
from pathlib import Path
from database import Database
from config import settings

logger = logging.getLogger(__name__)

class DatabaseMaintenance:
    def __init__(self, db: Database):
        """
        :param db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.db = db
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
    
    async def cleanup_old_records(self, days: int = 30):
        """
        å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
        :param days: ä½•æ—¥ä»¥å‰ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã™ã‚‹ã‹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30æ—¥)
        """
        logger.info(f"ğŸ—‘ï¸  å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤é–‹å§‹ (>{days}æ—¥å‰)")
        
        try:
            cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
            
            # æŠ•ç¨¿å±¥æ­´ã®å‰Šé™¤
            async with self.db.db.execute(
                "DELETE FROM posts WHERE posted_at < ?",
                (cutoff_date,)
            ) as cursor:
                await self.db.db.commit()
                deleted_posts = cursor.rowcount if hasattr(cursor, 'rowcount') else 0
                logger.info(f"  - æŠ•ç¨¿å±¥æ­´å‰Šé™¤: {deleted_posts}ä»¶")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å‰Šé™¤
            async with self.db.db.execute(
                "DELETE FROM reply_rate_limits WHERE replied_at < ?",
                (cutoff_date,)
            ) as cursor:
                await self.db.db.commit()
                deleted_rate_limits = cursor.rowcount if hasattr(cursor, 'rowcount') else 0
                logger.info(f"  - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤: {deleted_rate_limits}ä»¶")
            
            # VACUUMå®Ÿè¡Œ (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–)
            await self.db.db.execute("VACUUM")
            logger.info("  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–å®Œäº† (VACUUM)")
            
            logger.info(f"âœ… å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤å®Œäº†: æŠ•ç¨¿{deleted_posts}ä»¶, ãƒ¬ãƒ¼ãƒˆåˆ¶é™{deleted_rate_limits}ä»¶")
            
        except Exception as e:
            logger.error(f"å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def backup_database(self, compress: bool = True):
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        :param compress: gzipåœ§ç¸®ã™ã‚‹ã‹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTrue)
        :return: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        logger.info("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å (ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"bot_backup_{timestamp}.db"
            backup_path = self.backup_dir / backup_filename
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            db_path = Path(settings.database_path)
            if not db_path.exists():
                logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
                return None
            
            shutil.copy2(db_path, backup_path)
            logger.info(f"  - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
            
            # gzipåœ§ç¸®
            if compress:
                compressed_path = backup_path.with_suffix('.db.gz')
                with open(backup_path, 'rb') as f_in:
                    with gzip.open(compressed_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                
                # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                backup_path.unlink()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
                original_size = db_path.stat().st_size / 1024  # KB
                compressed_size = compressed_path.stat().st_size / 1024  # KB
                compression_ratio = (1 - compressed_size / original_size) * 100
                
                logger.info(f"  - åœ§ç¸®å®Œäº†: {compressed_path}")
                logger.info(f"  - åœ§ç¸®ç‡: {compression_ratio:.1f}% ({original_size:.1f}KB â†’ {compressed_size:.1f}KB)")
                
                backup_path = compressed_path
            else:
                size = backup_path.stat().st_size / 1024  # KB
                logger.info(f"  - ã‚µã‚¤ã‚º: {size:.1f}KB")
            
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_path}")
            return str(backup_path)
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def cleanup_old_backups(self, keep_count: int = 7):
        """
        å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        :param keep_count: ä¿æŒã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ7å€‹)
        """
        logger.info(f"ğŸ—‘ï¸  å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤é–‹å§‹ (æœ€æ–°{keep_count}å€‹ã‚’ä¿æŒ)")
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾— (ä½œæˆæ—¥æ™‚é †)
            backup_files = sorted(
                self.backup_dir.glob("bot_backup_*.db*"),
                key=lambda p: p.stat().st_mtime,
                reverse=True
            )
            
            # ä¿æŒæ•°ã‚’è¶…ãˆãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            deleted_count = 0
            for backup_file in backup_files[keep_count:]:
                backup_file.unlink()
                logger.info(f"  - å‰Šé™¤: {backup_file.name}")
                deleted_count += 1
            
            if deleted_count > 0:
                logger.info(f"âœ… å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤å®Œäº†: {deleted_count}ä»¶")
            else:
                logger.info("  - å‰Šé™¤å¯¾è±¡ãªã—")
                
        except Exception as e:
            logger.error(f"å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def get_database_stats(self) -> dict:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        :return: çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        try:
            stats = {}
            
            # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
            async with self.db.db.execute("SELECT COUNT(*) FROM followers") as cursor:
                result = await cursor.fetchone()
                stats['followers_count'] = result[0] if result else 0
            
            # æŠ•ç¨¿æ•°
            async with self.db.db.execute("SELECT COUNT(*) FROM posts") as cursor:
                result = await cursor.fetchone()
                stats['posts_count'] = result[0] if result else 0
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
            async with self.db.db.execute("SELECT COUNT(*) FROM reply_rate_limits") as cursor:
                result = await cursor.fetchone()
                stats['rate_limit_records'] = result[0] if result else 0
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            db_path = Path(settings.database_path)
            if db_path.exists():
                stats['db_size_kb'] = db_path.stat().st_size / 1024
            else:
                stats['db_size_kb'] = 0
            
            # æœ€å¤ãƒ»æœ€æ–°ã®æŠ•ç¨¿æ—¥æ™‚
            async with self.db.db.execute(
                "SELECT MIN(posted_at), MAX(posted_at) FROM posts"
            ) as cursor:
                result = await cursor.fetchone()
                if result and result[0]:
                    stats['oldest_post'] = result[0]
                    stats['newest_post'] = result[1]
                else:
                    stats['oldest_post'] = None
                    stats['newest_post'] = None
            
            return stats
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    async def log_database_stats(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        stats = await self.get_database_stats()
        
        if not stats:
            logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±:")
        logger.info(f"  - ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°: {stats.get('followers_count', 0)}äºº")
        logger.info(f"  - æŠ•ç¨¿å±¥æ­´: {stats.get('posts_count', 0)}ä»¶")
        logger.info(f"  - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ¬ã‚³ãƒ¼ãƒ‰: {stats.get('rate_limit_records', 0)}ä»¶")
        logger.info(f"  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {stats.get('db_size_kb', 0):.2f}KB")
        
        if stats.get('oldest_post'):
            logger.info(f"  - æœ€å¤ã®æŠ•ç¨¿: {stats['oldest_post'][:19]}")
            logger.info(f"  - æœ€æ–°ã®æŠ•ç¨¿: {stats['newest_post'][:19]}")
