"""
ãƒ­ã‚°ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»åœ§ç¸®ãƒ»å‰Šé™¤
"""

import logging
import gzip
import shutil
from datetime import datetime, timedelta
from pathlib import Path

logger = logging.getLogger(__name__)

class LogMaintenance:
    def __init__(self, log_dir: str = "logs"):
        """
        :param log_dir: ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
    
    def rotate_log(self, log_filename: str = "bot.log"):
        """
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ (ãƒªãƒãƒ¼ãƒ  + åœ§ç¸®)
        :param log_filename: ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        logger.info(f"ğŸ”„ ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹: {log_filename}")
        
        try:
            log_file = self.log_dir / log_filename
            
            if not log_file.exists():
                logger.warning(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {log_file}")
                return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            size_mb = log_file.stat().st_size / (1024 * 1024)
            logger.info(f"  - ç¾åœ¨ã®ã‚µã‚¤ã‚º: {size_mb:.2f}MB")
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            rotated_filename = f"{log_file.stem}_{timestamp}{log_file.suffix}"
            rotated_path = self.log_dir / rotated_filename
            
            # ãƒªãƒãƒ¼ãƒ 
            shutil.move(log_file, rotated_path)
            logger.info(f"  - ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {rotated_filename}")
            
            # gzipåœ§ç¸®
            compressed_path = rotated_path.with_suffix(f"{rotated_path.suffix}.gz")
            with open(rotated_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            rotated_path.unlink()
            
            compressed_size_mb = compressed_path.stat().st_size / (1024 * 1024)
            compression_ratio = (1 - compressed_size_mb / size_mb) * 100
            
            logger.info(f"  - åœ§ç¸®å®Œäº†: {compressed_path.name}")
            logger.info(f"  - åœ§ç¸®ç‡: {compression_ratio:.1f}% ({size_mb:.2f}MB â†’ {compressed_size_mb:.2f}MB)")
            logger.info(f"âœ… ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
    
    def cleanup_old_logs(self, days: int = 30, pattern: str = "bot_*.log.gz"):
        """
        å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        :param days: ä½•æ—¥ä»¥å‰ã®ãƒ­ã‚°ã‚’å‰Šé™¤ã™ã‚‹ã‹
        :param pattern: å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        """
        logger.info(f"ğŸ—‘ï¸  å¤ã„ãƒ­ã‚°å‰Šé™¤é–‹å§‹ (>{days}æ—¥å‰)")
        
        try:
            cutoff_time = datetime.now() - timedelta(days=days)
            deleted_count = 0
            deleted_size = 0
            
            for log_file in self.log_dir.glob(pattern):
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’ãƒã‚§ãƒƒã‚¯
                mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                
                if mtime < cutoff_time:
                    size = log_file.stat().st_size
                    log_file.unlink()
                    logger.info(f"  - å‰Šé™¤: {log_file.name} ({size / 1024:.1f}KB)")
                    deleted_count += 1
                    deleted_size += size
            
            if deleted_count > 0:
                logger.info(f"âœ… å¤ã„ãƒ­ã‚°å‰Šé™¤å®Œäº†: {deleted_count}ä»¶ ({deleted_size / (1024 * 1024):.2f}MB)")
            else:
                logger.info("  - å‰Šé™¤å¯¾è±¡ãªã—")
                
        except Exception as e:
            logger.error(f"å¤ã„ãƒ­ã‚°å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_log_stats(self) -> dict:
        """
        ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        :return: çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        try:
            stats = {
                'total_files': 0,
                'total_size_mb': 0,
                'active_log_size_mb': 0,
                'archived_count': 0,
                'archived_size_mb': 0
            }
            
            # å…¨ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èµ°æŸ»
            for log_file in self.log_dir.glob("*"):
                if not log_file.is_file():
                    continue
                
                size_mb = log_file.stat().st_size / (1024 * 1024)
                stats['total_files'] += 1
                stats['total_size_mb'] += size_mb
                
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ­ã‚°
                if log_file.name == "bot.log":
                    stats['active_log_size_mb'] = size_mb
                
                # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ­ã‚°
                if log_file.suffix == ".gz":
                    stats['archived_count'] += 1
                    stats['archived_size_mb'] += size_mb
            
            return stats
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def log_stats(self):
        """ãƒ­ã‚°çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        stats = self.get_log_stats()
        
        if not stats:
            logger.warning("ãƒ­ã‚°çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        logger.info("ğŸ“Š ãƒ­ã‚°çµ±è¨ˆæƒ…å ±:")
        logger.info(f"  - ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files']}å€‹")
        logger.info(f"  - ç·ã‚µã‚¤ã‚º: {stats['total_size_mb']:.2f}MB")
        logger.info(f"  - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ­ã‚°: {stats['active_log_size_mb']:.2f}MB")
        logger.info(f"  - ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ­ã‚°: {stats['archived_count']}å€‹ ({stats['archived_size_mb']:.2f}MB)")
