"""
Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (æ–°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç‰ˆ - MAX_TOKENS å•é¡Œä¿®æ­£ç‰ˆ)
google.genai ã‚’ä½¿ç”¨ (google.generativeai ã‹ã‚‰ã®ç§»è¡Œ)
"""

import logging
from google import genai
from google.genai import types
from config import settings

logger = logging.getLogger(__name__)

class GeminiClient:
    def __init__(self):
        """Gemini API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–"""
        # API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
        self.client = genai.Client(api_key=settings.gemini_api_key)
        
        # ãƒ¢ãƒ‡ãƒ«å
        self.model_name = "gemini-2.5-flash"
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿
        self.character_prompt = self._load_character_prompt()
        
        logger.info(f"âœ… Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº† ({self.model_name})")
        logger.info(f"ğŸ“ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {len(self.character_prompt)} æ–‡å­—èª­ã¿è¾¼ã¿")
    
    def _load_character_prompt(self) -> str:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        try:
            with open("katariina_prompt.md", "r", encoding="utf-8") as f:
                prompt = f.read()
            logger.debug("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿æˆåŠŸ")
            return prompt
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"
    
    async def generate_random_post(self) -> str:
        """
        ãƒ©ãƒ³ãƒ€ãƒ æŠ•ç¨¿ã‚’ç”Ÿæˆ
        :return: æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆ (140æ–‡å­—ä»¥å†…) ã¾ãŸã¯ None (ã‚¨ãƒ©ãƒ¼æ™‚)
        """
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (system_instruction ã¨ã¯åˆ¥)
            user_prompt = """ä»¥ä¸‹ã®æ¡ä»¶ã§ã€Misskeyã«æŠ•ç¨¿ã™ã‚‹ç‹¬ã‚Šè¨€ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:
- 140æ–‡å­—ä»¥å†…
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚‰ã—ã„è‡ªç„¶ãªå£èª¿
- æ—¥å¸¸çš„ãªå†…å®¹ã€æ°—åˆ†ã€è€ƒãˆã¦ã„ã‚‹ã“ã¨
- çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨
- è¿”ä¿¡ã§ã¯ãªãã€ç‹¬ç«‹ã—ãŸæŠ•ç¨¿

æŠ•ç¨¿å†…å®¹ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ã‚„å‰ç½®ãã¯ä¸è¦ï¼‰:"""

            # GenerateContentConfig ã‚’ä½¿ç”¨ (system_instruction ã¨ã—ã¦è¨­å®š)
            config = types.GenerateContentConfig(
                system_instruction=self.character_prompt,
                temperature=1.0,
                max_output_tokens=1024  # â† 512â†’1024 ã«å¢—é‡ï¼ˆæ—¥æœ¬èªã¯1æ–‡å­—=4ã€œ5ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
            )
            
            # generate_content ã‚’ä½¿ç”¨
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=user_prompt,
                config=config
            )
            
            # finish_reason ãƒã‚§ãƒƒã‚¯
            if response.candidates and response.candidates[0].finish_reason != types.FinishReason.STOP:
                logger.warning(f"âš ï¸ finish_reason: {response.candidates[0].finish_reason}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            content = response.text.strip()
            
            # æ”¹è¡Œå‰Šé™¤
            if '\n' in content:
                content = content.replace('\n', ' ').replace('  ', ' ')
            
            # 140æ–‡å­—è¶…éãƒã‚§ãƒƒã‚¯
            if len(content) > 140:
                logger.info(f"ğŸ“ {len(content)}æ–‡å­—ã‚’140æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚")
                content = content[:140]
            
            logger.info(f"âœ… ãƒ©ãƒ³ãƒ€ãƒ æŠ•ç¨¿ç”ŸæˆæˆåŠŸ ({len(content)}æ–‡å­—): {content}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ Gemini API ã‚¨ãƒ©ãƒ¼ (ãƒ©ãƒ³ãƒ€ãƒ æŠ•ç¨¿): {e}")
            logger.exception("è©³ç´°:")
            return None
    
    async def generate_reply(self, user_message: str, username: str) -> str:
        """
        ãƒªãƒ—ãƒ©ã‚¤ã‚’ç”Ÿæˆ
        :param user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        :param username: ãƒ¦ãƒ¼ã‚¶ãƒ¼å
        :return: ãƒªãƒ—ãƒ©ã‚¤ãƒ†ã‚­ã‚¹ãƒˆ (140æ–‡å­—ä»¥å†…) ã¾ãŸã¯ None (ã‚¨ãƒ©ãƒ¼æ™‚)
        """
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (çŸ­ã™ãã‚‹ã®ã‚’é˜²ããŸã‚ã€ç›®å®‰ã‚’æ˜ç¤º)
            user_prompt = f"""@{username} ã•ã‚“ã‹ã‚‰ã®ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³:
ã€Œ{user_message}ã€

ä»¥ä¸‹ã®æ¡ä»¶ã§è¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:
- 50ã€œ120æ–‡å­—ç¨‹åº¦ (çŸ­ã™ããšã€é•·ã™ããš)
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚‰ã—ã„è‡ªç„¶ãªå£èª¿
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã«é©åˆ‡ã«å¿œç­”
- è¦ªã—ã¿ã‚„ã™ãã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¿”ä¿¡
- çµµæ–‡å­—ã¯æ§ãˆã‚ã« (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã†)

è¿”ä¿¡å†…å®¹ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ã‚„å‰ç½®ãã¯ä¸è¦ï¼‰:"""

            # GenerateContentConfig ã‚’ä½¿ç”¨ (system_instruction ã¨ã—ã¦è¨­å®š)
            config = types.GenerateContentConfig(
                system_instruction=self.character_prompt,
                temperature=1.0,
                max_output_tokens=1024,  # â† 512â†’1024 ã«å¢—é‡
                candidate_count=1
            )
            
            # generate_content ã‚’ä½¿ç”¨
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=user_prompt,
                config=config
            )
            
            # finish_reason ãƒã‚§ãƒƒã‚¯
            if response.candidates:
                finish_reason = response.candidates[0].finish_reason
                if finish_reason != types.FinishReason.STOP:
                    logger.warning(f"âš ï¸ finish_reason: {finish_reason} (MAX_TOKENSã®å¯èƒ½æ€§)")
            
            # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            content = response.text.strip()
            
            # æ”¹è¡Œå‰Šé™¤
            if '\n' in content:
                content = content.replace('\n', ' ').replace('  ', ' ')
            
            # 140æ–‡å­—è¶…éãƒã‚§ãƒƒã‚¯
            if len(content) > 140:
                logger.info(f"ğŸ“ {len(content)}æ–‡å­—ã‚’140æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚")
                content = content[:140]
            
            logger.info(f"âœ… ãƒªãƒ—ãƒ©ã‚¤ç”ŸæˆæˆåŠŸ ({len(content)}æ–‡å­—): {content}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ Gemini API ã‚¨ãƒ©ãƒ¼ (ãƒªãƒ—ãƒ©ã‚¤): {e}")
            logger.exception("è©³ç´°ã‚¨ãƒ©ãƒ¼:")
            return None
